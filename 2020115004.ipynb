{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":74586,"databundleVersionId":8130765,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom os.path import join\nfrom pathlib import Path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:41:40.443192Z","iopub.execute_input":"2024-04-26T14:41:40.443831Z","iopub.status.idle":"2024-04-26T14:41:40.450562Z","shell.execute_reply.started":"2024-04-26T14:41:40.443799Z","shell.execute_reply":"2024-04-26T14:41:40.449563Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom os.path import join\nfrom pathlib import Path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, ColorJitter\nimport torch.optim as optim\n\nclass AgeDataset(torch.utils.data.Dataset):\n\n    def __init__(self, data_path, annot_path, train=True):\n        super(AgeDataset, self).__init__()\n\n        self.annot_path = annot_path\n        self.data_path = data_path\n        self.train = train\n\n        self.ann = pd.read_csv(annot_path)\n        self.files = self.ann['file_id']\n        if train:\n            self.ages = self.ann['age']\n        self.transform = self._transform(224)\n\n    @staticmethod    \n    def _convert_image_to_rgb(image):\n        return image.convert(\"RGB\")\n\n    def _transform(self, n_px):\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n        if self.train:\n            return Compose([\n                Resize((n_px, n_px)),\n                RandomHorizontalFlip(),  # Data augmentation\n                RandomRotation(15),  # Data augmentation\n                ColorJitter(brightness=0.5, contrast=0.5),  # Data augmentation\n                ToTensor(),\n                Normalize(mean, std),\n            ])\n        else:\n            return Compose([\n                Resize((n_px, n_px)),\n                ToTensor(),\n                Normalize(mean, std),\n            ])\n\n    def read_img(self, file_name):\n        im_path = join(self.data_path,file_name)   \n        img = Image.open(im_path)\n        img = self.transform(img)\n        return img\n\n    def __getitem__(self, index):\n        file_name = self.files[index]\n        img = self.read_img(file_name)\n        if self.train:\n            age = self.ages[index]\n            return img, age\n        else:\n            return img\n\n    def __len__(self):\n        return len(self.files)\n\n\ntrain_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train'\ntrain_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv'\ntrain_dataset = AgeDataset(train_path, train_ann, train=True)\n\n\ntest_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/test'\ntest_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/submission.csv'\ntest_dataset = AgeDataset(test_path, test_ann, train=False)\n\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=4)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:47:47.727275Z","iopub.execute_input":"2024-04-26T14:47:47.727626Z","iopub.status.idle":"2024-04-26T14:47:47.768483Z","shell.execute_reply.started":"2024-04-26T14:47:47.727600Z","shell.execute_reply":"2024-04-26T14:47:47.767639Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:47:52.292247Z","iopub.execute_input":"2024-04-26T14:47:52.293095Z","iopub.status.idle":"2024-04-26T14:47:52.297684Z","shell.execute_reply.started":"2024-04-26T14:47:52.293061Z","shell.execute_reply":"2024-04-26T14:47:52.296715Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"667\n","output_type":"stream"}]},{"cell_type":"code","source":"import torchvision.models as models\n\npretrained_model = models.resnet18(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:49:15.549409Z","iopub.execute_input":"2024-04-26T14:49:15.550267Z","iopub.status.idle":"2024-04-26T14:49:15.798590Z","shell.execute_reply.started":"2024-04-26T14:49:15.550237Z","shell.execute_reply":"2024-04-26T14:49:15.797708Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"class AgeModel(nn.Module):\n    def __init__(self):\n        super(AgeModel, self).__init__()\n        self.model = models.resnet18(pretrained=True)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Sequential(\n            nn.BatchNorm1d(num_ftrs),\n            nn.Dropout(0.5),\n            nn.Linear(num_ftrs, 1)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n# Instantiate the model\nmodel = AgeModel().to(device)\n\n# Define hyperparameters for tuning\nlearning_rates = [0.001, 0.0001]\nbatch_sizes = [32, 64]\nbest_loss = float('inf')\n\nfor lr in learning_rates:\n    for batch_size in batch_sizes:\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n        criterion = nn.MSELoss()\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        # Learning rate scheduler\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n        \n        print(f'Training with learning rate: {lr} and batch size: {batch_size}')\n        for epoch in range(20):  # Set the number of epochs\n            model.train()\n            running_loss = 0.0\n            for i, data in enumerate(train_loader):\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs.squeeze(), labels.float())\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n            \n            # Update the learning rate\n            scheduler.step()\n            \n            # Print loss\n            epoch_loss = running_loss / len(train_loader)\n            print(f'Epoch {epoch+1}, Loss: {epoch_loss}')\n            \n            # Checkpoint the best model\n            if epoch_loss < best_loss:\n                best_loss = epoch_loss\n                best_lr = lr\n                best_batch_size = batch_size\n                torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n\nprint(f'Best model trained with learning rate: {best_lr} and batch size: {best_batch_size}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T14:49:56.318358Z","iopub.execute_input":"2024-04-26T14:49:56.318731Z","iopub.status.idle":"2024-04-26T16:19:26.922432Z","shell.execute_reply.started":"2024-04-26T14:49:56.318703Z","shell.execute_reply":"2024-04-26T16:19:26.921002Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Training with learning rate: 0.001 and batch size: 32\nEpoch 1, Loss: 405.9693109034777\nEpoch 2, Loss: 108.82769402499677\nEpoch 3, Loss: 94.91048342749097\nEpoch 4, Loss: 88.19894201573224\nEpoch 5, Loss: 81.70181176044058\nEpoch 6, Loss: 77.6725676649514\nEpoch 7, Loss: 75.43683787550347\nEpoch 8, Loss: 61.12171602606595\nEpoch 9, Loss: 59.21905563045656\nEpoch 10, Loss: 55.8144586382956\nEpoch 11, Loss: 55.58751121418051\nEpoch 12, Loss: 55.0830676151716\nEpoch 13, Loss: 53.763831862087905\nEpoch 14, Loss: 52.66518777278231\nEpoch 15, Loss: 49.883850463684176\nEpoch 16, Loss: 51.11191272592616\nEpoch 17, Loss: 49.67688494000299\nEpoch 18, Loss: 49.776413824604724\nEpoch 19, Loss: 50.32285289392657\nEpoch 20, Loss: 48.04576221506099\nTraining with learning rate: 0.001 and batch size: 64\nEpoch 1, Loss: 57.518322733348\nEpoch 2, Loss: 56.0339717122609\nEpoch 3, Loss: 53.43655329264566\nEpoch 4, Loss: 53.95883481945106\nEpoch 5, Loss: 50.3409277636134\nEpoch 6, Loss: 48.98520697519451\nEpoch 7, Loss: 47.58119245060904\nEpoch 8, Loss: 41.827146587257616\nEpoch 9, Loss: 38.9176106481495\nEpoch 10, Loss: 38.41601150763963\nEpoch 11, Loss: 37.35211270726369\nEpoch 12, Loss: 36.50515908109928\nEpoch 13, Loss: 35.129487620142406\nEpoch 14, Loss: 34.766174650477794\nEpoch 15, Loss: 34.525588897887815\nEpoch 16, Loss: 34.3113744701454\nEpoch 17, Loss: 34.37202539843713\nEpoch 18, Loss: 34.245918588010134\nEpoch 19, Loss: 34.0481639079705\nEpoch 20, Loss: 33.229146997371835\nTraining with learning rate: 0.0001 and batch size: 32\nEpoch 1, Loss: 39.5864637437789\nEpoch 2, Loss: 39.079623363900936\nEpoch 3, Loss: 38.13542513296879\nEpoch 4, Loss: 38.016931213539046\nEpoch 5, Loss: 37.196000251455466\nEpoch 6, Loss: 38.02710932198314\nEpoch 7, Loss: 37.077717798224455\nEpoch 8, Loss: 34.77157942930619\nEpoch 9, Loss: 35.16700695443904\nEpoch 10, Loss: 35.14467369348392\nEpoch 11, Loss: 35.11318217224624\nEpoch 12, Loss: 35.22579070438688\nEpoch 13, Loss: 34.4924396174601\nEpoch 14, Loss: 33.367634680317614\nEpoch 15, Loss: 34.62635504395172\nEpoch 16, Loss: 34.405501155481524\nEpoch 17, Loss: 33.66303448198081\nEpoch 18, Loss: 34.24860955571485\nEpoch 19, Loss: 34.06258541032828\nEpoch 20, Loss: 34.72845672167045\nTraining with learning rate: 0.0001 and batch size: 64\nEpoch 1, Loss: 29.2739562931175\nEpoch 2, Loss: 30.03388581590024\nEpoch 3, Loss: 29.105435120131443\nEpoch 4, Loss: 28.463972928281315\nEpoch 5, Loss: 27.543784695471118\nEpoch 6, Loss: 27.527631908119794\nEpoch 7, Loss: 28.356987967462597\nEpoch 8, Loss: 27.54706771073941\nEpoch 9, Loss: 25.678647326852033\nEpoch 10, Loss: 25.09353692517309\nEpoch 11, Loss: 26.58103190210765\nEpoch 12, Loss: 25.600796294069575\nEpoch 13, Loss: 26.00348951716623\nEpoch 14, Loss: 25.665109014796638\nEpoch 19, Loss: 25.555606325229483\nEpoch 20, Loss: 25.650222207257848\nBest model trained with learning rate: 0.0001 and batch size: 64\n","output_type":"stream"}]},{"cell_type":"code","source":"@torch.no_grad\n\ndef predict(loader, model):\n    model.eval()\n    predictions = []\n\n    for img in tqdm(loader):\n        img = img.to(device)\n\n        pred = model(img)\n        predictions.extend(pred.flatten().detach().tolist())\n\n    return predictions\n\npreds = predict(test_loader, model)\n\nsubmit = pd.read_csv('/kaggle/input/smai-24-age-prediction/content/faces_dataset/submission.csv')\nsubmit['age'] = preds\nsubmit.head()\n\nsubmit.to_csv('baseline.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T16:19:56.690900Z","iopub.execute_input":"2024-04-26T16:19:56.691634Z","iopub.status.idle":"2024-04-26T16:20:06.047970Z","shell.execute_reply.started":"2024-04-26T16:19:56.691594Z","shell.execute_reply":"2024-04-26T16:20:06.046837Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 31/31 [00:09<00:00,  3.32it/s]\n","output_type":"stream"}]}]}